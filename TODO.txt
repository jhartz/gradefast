TODO
====

GradeBook TODOs:

- "code" blocks in the Overall Comments section (in the gradebook) are "whited out" (since the text
  is white, and the code block background is white)
- Use getters and setters in a consistent way in grades.py
- Add "late_deduction_percent" to get_data(), ONLY if is_late is true and we actually deducted
  something
- In list of submissions, include button to open the submission folder
- When opening the list of submissions, make sure we're scrolled all the way to the top
- Use more specific exceptions all over instead of creating a GradeBookPublicException manually
- Allow changing the name of a grade item by clicking on the title in the gradebook (this will only
  change it for that submission)
- Allow changing the submission name ("SET_SUBMISSION_NAME", so it's distinct from "GRADE_SET_NAME")
- Allow changing the late deduction for a particular submission.
    - When you check the "Late" checkbox, show "-xx%" next to it, which you can click on to change.
- Allow editing notes for a grade item (this will only change it for that submission) -- OR maybe
  not; I could see this causing some major confusion on notes vs comments.
- Checkbox in submissions dropdown to hide submission names throughout the gradebook, to try to
  prevent bias
- Write tests for grade structure parser, and grades.py
- In the gradebook (particularly gradebook.grades and the UI), find something better to call the
  path to the grade item than "path" (it's confusing with the Path model for filesystem paths).
- For sections, add a "scale" option that takes a ratio to scale the section by (or a string
  representing a fraction)
- For grade structures, add "collapsible" option to collapse the structure if it's either 0 or 100%
  (and with no hints/comments, and all grade items are exactly full points)
- 3 states for grade structures: enabled, disabled, or collapsed, in which case any sub grades are
  not shown, and we just enter one big point value, one big comment. This probably means
  implementing a custom checkbox, or doing something hacky like: https://jsfiddle.net/urtwh9t7/2/
- Bar charts for the statistics in the submissions dropdown
    - For timing: show "stacked" bars if we revisited a submission multiple times in the grader
    - If we generate server-side: it's easier to save
    - If we generate client-side: we can provide more info on mouseover, like the actual start/end
      times, and can sort differently, etc.

Grader TODOs:

- Look into the process group stuff, and try to get it to where we want it (where Ctrl+C kills, and
  another Ctrl+C terminates, but neither affects any background commands).
    - subprocess.CREATE_NEW_PROCESS_GROUP, and make sure we catch Ctrl-C properly and do
      process.terminate() (for the current foreground process, and for background processes when
      we're in the "waiting" stage). Also test the current functionality on Linux; and this might
      be useful: http://stackoverflow.com/questions/18255730/popen-new-process-group-on-linux
    - NOTE: If we have subprocesses be in their own group, then they might not die if GradeFast
      crashes! So, this might not be what we want.
    - Look at the Popen.send_signal docs: https://docs.python.org/3/library/subprocess.html#subprocess.Popen.send_signal
    - Test on Windows, Mac, and Linux.
- Fix issues with stdout "buffering" (until the program exits) when we...
    a) have stdin specified in yaml file,
    b) and are using turtle graphics (at least in the tests I've been doing)
- Don't re-add duplicate submissions (when adding a new submission, check if it's "in" the dict
  already, i.e. check equality on "path")
- Add a diff config option for whether to show the raw output as it comes in (since we need to wait
  for the process to end before we do the diff).
  - Pros: you get to see that the command is running, and provide input if needed.
  - Cons: double output. (Should probably still be enabled by default, though).
  - We could also have an option to capture user input and include that in the diffing
- Make a section in the YAML commands to take the output of a command (or the last line of output)
  and use that as the grade for a certain grading item (identified by name) -- OR to use the
  output as the comment for a grade item
- Make "pre-run" and "post-cleanup" sections in the YAML file with commands to run before starting
  any grading, and after all the grading is complete. (Store that the pre-run was run so that it'll
  store in the savefile)
- Option to "steal back" terminal/cmd window focus after running a command
    - For iTerm on macs: https://www.iterm2.com/documentation-escape-codes.html
- When running a command, ask the user if they want to skip doing the diff, or to enter a different
  diff filename. (same w/ being able to skip stdin)
- Add ability to specify a max running time for a process (useful for background commands), and
  then some sort of action if it's cut off (like above idea of using program output as comment text)
- For command sets, add ability to specify required files that must be in the folder (we'll do a BFS
  thru sub-folders to find the first that matches the requirement)
    - "find subfolder with": ["file1", "file2", ...] (or just a single filename string)
    - If we can't find one, "error" it and just use the root folder
- Ability to filter which lines of output are shown based on a regex (w/ "context", i.e. x lines
  before/after)

Big TODOs:

- In grade book, make a "note book" where we store commonly used notes, and we can access it by
  right-clicking in any of the comment boxes and it brings it up, and we can click on something to
  insert it at that point, or add a new one. It would show at the top the ones that were created on
  the comment box where we right-clicked, and then below it the ones created on other boxes.
    - More useful alternative: right-clicking just shows snippets of previous content of that box
    - Although they really should've been using hints :p
- Add "shortcut" command to open a list of files in a given editor (or maybe just another option on
  a command to append this list to the end of the parameters). Then we can have an order for the
  files, and any extra other files in the dir can be appended to the end of the list.
- Make separate python script to parse the index.html from Desire2Learn platforms to add metadata
  for submissions (so we can take the comments they wrote when uploading, and also possibly whether
  it was late)
    - Also in this script if we have multiple submissions by the same person, run a checksum on
      them to make sure they're different and, if not, delete the earlier one
    - Actually, in general, delete the earlier one for any submissions that have multiple
      submissions (unless one is on time and other is late)
    - FUN PART: How can we set a "default late" and "overall notes" for submissions on a
      per-submission basis? Maybe a file in the root of the submission called "GRADEFAST.META.YAML"
- Macros in YAML file (that's just a blanket string-replace)
    - Wherever a string is provided in the YAML file, we could instead say "_parse: ...str..."
    - Anywhere in the file, we can say "_define: {NAME: VALUE, ...}"
    - Use str.format
    - The parsing all happens right when the YAML file is read in, before it hits up anything in
      parsers.py
